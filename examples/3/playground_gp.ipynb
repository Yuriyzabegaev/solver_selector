{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from data_scripts import get_newest_data_paths\n",
    "from mandel_model import make_mandel_setup\n",
    "from mandel_solvers import make_mandel_solver_space\n",
    "\n",
    "from solver_selector.simulation_runner import make_simulation_runner\n",
    "\n",
    "path = Path().parent / \"../2\"\n",
    "load_data_paths = []\n",
    "load_data_paths += get_newest_data_paths(path / \"poro_coldstart_s\", n_newest=1)\n",
    "load_data_paths += get_newest_data_paths(path / \"poro_coldstart_m\", n_newest=1)\n",
    "load_data_paths += get_newest_data_paths('poro_coldstart_gp', n_newest=1)\n",
    "\n",
    "# assert len(load_data_paths) == 3\n",
    "\n",
    "solver_space = make_mandel_solver_space(l_factor=\"dynamic\")\n",
    "simulation = make_mandel_setup(model_size=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting from 1 solvers.\n",
      "0 gmres - splitting_fixed_stress [primary - direct, secondary - direct, l_factor=0, primary_variable, method]\n",
      "Using epsilon-greedy exploration\n",
      "Using regressor: gradient_boosting\n",
      "Warm start using data:\n",
      "/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/../2/performance/poro_coldstart_s_11.npy\n",
      "/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/../2/performance/poro_coldstart_m_10.npy\n",
      "/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/performance/poro_coldstart_gp_13.npy\n"
     ]
    }
   ],
   "source": [
    "simulation_runner = make_simulation_runner(\n",
    "    solver_space=solver_space,\n",
    "    params={\n",
    "        \"load_statistics_paths\": load_data_paths,\n",
    "        \"print_solver\": True,\n",
    "        # \"predictor\": \"gaussian_process\",\n",
    "        # 'regressor': 'mlp',\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>ms</th>\n",
       "      <th>cfl_mean</th>\n",
       "      <th>cfl_max</th>\n",
       "      <th>l_factor</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000e+02</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>9.522425</td>\n",
       "      <td>4.763271</td>\n",
       "      <td>2.675042</td>\n",
       "      <td>0.554912</td>\n",
       "      <td>0.096044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.448312e-16</td>\n",
       "      <td>0.552540</td>\n",
       "      <td>0.683754</td>\n",
       "      <td>0.074138</td>\n",
       "      <td>0.165667</td>\n",
       "      <td>0.798898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>8.884333</td>\n",
       "      <td>4.250704</td>\n",
       "      <td>2.650625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.174203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>8.884333</td>\n",
       "      <td>4.380030</td>\n",
       "      <td>2.658094</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>-0.921008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>9.452816</td>\n",
       "      <td>4.566659</td>\n",
       "      <td>2.666993</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.254097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>10.230126</td>\n",
       "      <td>4.896762</td>\n",
       "      <td>2.672971</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.923850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.302585e+00</td>\n",
       "      <td>10.230126</td>\n",
       "      <td>9.988645</td>\n",
       "      <td>3.467773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.090734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts          ms    cfl_mean     cfl_max    l_factor  \\\n",
       "count  3.000000e+02  300.000000  300.000000  300.000000  300.000000   \n",
       "mean   2.302585e+00    9.522425    4.763271    2.675042    0.554912   \n",
       "std    4.448312e-16    0.552540    0.683754    0.074138    0.165667   \n",
       "min    2.302585e+00    8.884333    4.250704    2.650625    0.000000   \n",
       "25%    2.302585e+00    8.884333    4.380030    2.658094    0.526316   \n",
       "50%    2.302585e+00    9.452816    4.566659    2.666993    0.578947   \n",
       "75%    2.302585e+00   10.230126    4.896762    2.672971    0.631579   \n",
       "max    2.302585e+00   10.230126    9.988645    3.467773    1.000000   \n",
       "\n",
       "           target  \n",
       "count  300.000000  \n",
       "mean     0.096044  \n",
       "std      0.798898  \n",
       "min     -1.174203  \n",
       "25%     -0.921008  \n",
       "50%      0.254097  \n",
       "75%      0.923850  \n",
       "max      1.090734  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "predictor = simulation_runner.solver_selector.predictors[0]\n",
    "X = np.array(predictor.memory_contexts)\n",
    "y = np.array(predictor.memory_rewards)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['ts', 'ms', 'cfl_mean', 'cfl_max', 'l_factor'])\n",
    "data['target'] = y\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_mean = data.ts.mean()\n",
    "# data_max = data.ms.max() + (data.ms.max() - data.ms.min())\n",
    "data_max = data.ms.max()\n",
    "ms = np.linspace(data.ms.min(), data_max, 100)\n",
    "cfl_mean = data.cfl_mean.mean()\n",
    "cfl_max = data.cfl_max.mean()\n",
    "l_factor = np.linspace(data.l_factor.min(), data.l_factor.max(), 100)\n",
    "\n",
    "ms, l_factor = np.meshgrid(ms, l_factor, indexing='ij')\n",
    "\n",
    "data1 = np.zeros((5, 100, 100))\n",
    "data1[0] = ts_mean\n",
    "data1[1] = ms\n",
    "data1[2] = cfl_mean\n",
    "data1[3] = cfl_max\n",
    "data1[4] = l_factor\n",
    "data1 = data1.reshape(5, -1)\n",
    "data1 = data1.T\n",
    "\n",
    "target1 = predictor.regressor.predict(data1)\n",
    "df1 = pd.DataFrame(data1, columns=['ts', 'ms', 'cfl_mean', 'cfl_max', 'l_factor'])\n",
    "df1['target'] = target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean, std = predictor.regressor.predict(data1, return_std=True)\n",
    "# df1['target'] = mean + std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4c686e8ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash_app import make_app\n",
    "\n",
    "app = make_app([data, df1], ['ms', 'l_factor', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=5)\n",
    "            + gpytorch.kernels.LinearKernel(active_dims=[1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "\n",
    "# initialize likelihood and model\n",
    "predictor = simulation_runner.solver_selector.predictors[0]\n",
    "X = torch.Tensor(predictor.memory_contexts)\n",
    "y = torch.Tensor(predictor.memory_rewards)\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(X, y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firedrake/firedrake/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "\n",
      "/home/firedrake/firedrake/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/100 - Loss: 0.817   noise: 0.693\n",
      "Iter 2/100 - Loss: 0.778   noise: 0.644\n",
      "Iter 3/100 - Loss: 0.739   noise: 0.598\n",
      "Iter 4/100 - Loss: 0.700   noise: 0.554\n",
      "Iter 5/100 - Loss: 0.660   noise: 0.513\n",
      "Iter 6/100 - Loss: 0.620   noise: 0.474\n",
      "Iter 7/100 - Loss: 0.579   noise: 0.437\n",
      "Iter 8/100 - Loss: 0.537   noise: 0.403\n",
      "Iter 9/100 - Loss: 0.495   noise: 0.370\n",
      "Iter 10/100 - Loss: 0.452   noise: 0.340\n",
      "Iter 11/100 - Loss: 0.409   noise: 0.312\n",
      "Iter 12/100 - Loss: 0.366   noise: 0.286\n",
      "Iter 13/100 - Loss: 0.321   noise: 0.261\n",
      "Iter 14/100 - Loss: 0.277   noise: 0.239\n",
      "Iter 15/100 - Loss: 0.232   noise: 0.218\n",
      "Iter 16/100 - Loss: 0.186   noise: 0.198\n",
      "Iter 17/100 - Loss: 0.140   noise: 0.181\n",
      "Iter 18/100 - Loss: 0.094   noise: 0.164\n",
      "Iter 19/100 - Loss: 0.048   noise: 0.149\n",
      "Iter 20/100 - Loss: 0.001   noise: 0.136\n",
      "Iter 21/100 - Loss: -0.046   noise: 0.123\n",
      "Iter 22/100 - Loss: -0.093   noise: 0.112\n",
      "Iter 23/100 - Loss: -0.140   noise: 0.101\n",
      "Iter 24/100 - Loss: -0.188   noise: 0.092\n",
      "Iter 25/100 - Loss: -0.236   noise: 0.083\n",
      "Iter 26/100 - Loss: -0.283   noise: 0.075\n",
      "Iter 27/100 - Loss: -0.331   noise: 0.068\n",
      "Iter 28/100 - Loss: -0.379   noise: 0.061\n",
      "Iter 29/100 - Loss: -0.427   noise: 0.055\n",
      "Iter 30/100 - Loss: -0.475   noise: 0.050\n",
      "Iter 31/100 - Loss: -0.523   noise: 0.045\n",
      "Iter 32/100 - Loss: -0.570   noise: 0.041\n",
      "Iter 33/100 - Loss: -0.617   noise: 0.037\n",
      "Iter 34/100 - Loss: -0.664   noise: 0.033\n",
      "Iter 35/100 - Loss: -0.710   noise: 0.030\n",
      "Iter 36/100 - Loss: -0.756   noise: 0.027\n",
      "Iter 37/100 - Loss: -0.802   noise: 0.024\n",
      "Iter 38/100 - Loss: -0.847   noise: 0.022\n",
      "Iter 39/100 - Loss: -0.892   noise: 0.020\n",
      "Iter 40/100 - Loss: -0.935   noise: 0.018\n",
      "Iter 41/100 - Loss: -0.979   noise: 0.016\n",
      "Iter 42/100 - Loss: -1.021   noise: 0.015\n",
      "Iter 43/100 - Loss: -1.064   noise: 0.013\n",
      "Iter 44/100 - Loss: -1.106   noise: 0.012\n",
      "Iter 45/100 - Loss: -1.147   noise: 0.011\n",
      "Iter 46/100 - Loss: -1.190   noise: 0.010\n",
      "Iter 47/100 - Loss: -1.233   noise: 0.009\n",
      "Iter 48/100 - Loss: -1.277   noise: 0.008\n",
      "Iter 49/100 - Loss: -1.321   noise: 0.007\n",
      "Iter 50/100 - Loss: -1.366   noise: 0.007\n",
      "Iter 51/100 - Loss: -1.410   noise: 0.006\n",
      "Iter 52/100 - Loss: -1.452   noise: 0.006\n",
      "Iter 53/100 - Loss: -1.492   noise: 0.005\n",
      "Iter 54/100 - Loss: -1.530   noise: 0.005\n",
      "Iter 55/100 - Loss: -1.565   noise: 0.004\n",
      "Iter 56/100 - Loss: -1.598   noise: 0.004\n",
      "Iter 57/100 - Loss: -1.630   noise: 0.003\n",
      "Iter 58/100 - Loss: -1.660   noise: 0.003\n",
      "Iter 59/100 - Loss: -1.686   noise: 0.003\n",
      "Iter 60/100 - Loss: -1.714   noise: 0.003\n",
      "Iter 61/100 - Loss: -1.739   noise: 0.002\n",
      "Iter 62/100 - Loss: -1.761   noise: 0.002\n",
      "Iter 63/100 - Loss: -1.781   noise: 0.002\n",
      "Iter 64/100 - Loss: -1.800   noise: 0.002\n",
      "Iter 65/100 - Loss: -1.817   noise: 0.002\n",
      "Iter 66/100 - Loss: -1.834   noise: 0.002\n",
      "Iter 67/100 - Loss: -1.848   noise: 0.002\n",
      "Iter 68/100 - Loss: -1.859   noise: 0.001\n",
      "Iter 69/100 - Loss: -1.865   noise: 0.001\n",
      "Iter 70/100 - Loss: -1.875   noise: 0.001\n",
      "Iter 71/100 - Loss: -1.880   noise: 0.001\n",
      "Iter 72/100 - Loss: -1.883   noise: 0.001\n",
      "Iter 73/100 - Loss: -1.892   noise: 0.001\n",
      "Iter 74/100 - Loss: -1.893   noise: 0.001\n",
      "Iter 75/100 - Loss: -1.885   noise: 0.001\n",
      "Iter 76/100 - Loss: -1.890   noise: 0.001\n",
      "Iter 77/100 - Loss: -1.890   noise: 0.001\n",
      "Iter 78/100 - Loss: -1.882   noise: 0.001\n",
      "Iter 79/100 - Loss: -1.895   noise: 0.001\n",
      "Iter 80/100 - Loss: -1.880   noise: 0.001\n",
      "Iter 81/100 - Loss: -1.884   noise: 0.001\n",
      "Iter 82/100 - Loss: -1.879   noise: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/firedrake/firedrake/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:40: NumericalWarning:\n",
      "\n",
      "A not p.d., added jitter of 1.0e-04 to the diagonal\n",
      "\n"
     ]
    },
    {
     "ename": "NotPSDError",
     "evalue": "Matrix not positive definite after repeatedly adding jitter up to 1.0e-04.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotPSDError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m output \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Calc loss and backprop gradients\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mmll(output, y)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mIter \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m - Loss: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m   noise: \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, training_iter, loss\u001b[39m.\u001b[39mitem(),\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m# model.covar_module.base_kernel.lengthscale.item(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     model\u001b[39m.\u001b[39mlikelihood\u001b[39m.\u001b[39mnoise\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6b65656e5f6d6f6e74616c63696e69227d/home/firedrake/workspace/porepy_workspace/solver_selector/examples/3/playground_gp.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m ))\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/gpytorch/module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[0;32m---> 31\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py:64\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m     63\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlikelihood(function_dist, \u001b[39m*\u001b[39mparams)\n\u001b[0;32m---> 64\u001b[0m res \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39;49mlog_prob(target)\n\u001b[1;32m     65\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_other_terms(res, params)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:193\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m# Get log determininant and first part of quadratic form\u001b[39;00m\n\u001b[1;32m    192\u001b[0m covar \u001b[39m=\u001b[39m covar\u001b[39m.\u001b[39mevaluate_kernel()\n\u001b[0;32m--> 193\u001b[0m inv_quad, logdet \u001b[39m=\u001b[39m covar\u001b[39m.\u001b[39;49minv_quad_logdet(inv_quad_rhs\u001b[39m=\u001b[39;49mdiff\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), logdet\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    195\u001b[0m res \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m \u001b[39msum\u001b[39m([inv_quad, logdet, diff\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m math\u001b[39m.\u001b[39mpi)])\n\u001b[1;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:1701\u001b[0m, in \u001b[0;36mLinearOperator.inv_quad_logdet\u001b[0;34m(self, inv_quad_rhs, logdet, reduce_inv_quad)\u001b[0m\n\u001b[1;32m   1699\u001b[0m             will_need_cholesky \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     \u001b[39mif\u001b[39;00m will_need_cholesky:\n\u001b[0;32m-> 1701\u001b[0m         cholesky \u001b[39m=\u001b[39m CholLinearOperator(TriangularLinearOperator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcholesky()))\n\u001b[1;32m   1702\u001b[0m     \u001b[39mreturn\u001b[39;00m cholesky\u001b[39m.\u001b[39minv_quad_logdet(\n\u001b[1;32m   1703\u001b[0m         inv_quad_rhs\u001b[39m=\u001b[39minv_quad_rhs,\n\u001b[1;32m   1704\u001b[0m         logdet\u001b[39m=\u001b[39mlogdet,\n\u001b[1;32m   1705\u001b[0m         reduce_inv_quad\u001b[39m=\u001b[39mreduce_inv_quad,\n\u001b[1;32m   1706\u001b[0m     )\n\u001b[1;32m   1708\u001b[0m \u001b[39m# Short circuit to inv_quad function if we're not computing logdet\u001b[39;00m\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:1303\u001b[0m, in \u001b[0;36mLinearOperator.cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[39m@_implements\u001b[39m(torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mcholesky)\n\u001b[1;32m   1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcholesky\u001b[39m(\n\u001b[1;32m   1295\u001b[0m     \u001b[39mself\u001b[39m: Float[LinearOperator, \u001b[39m\"\u001b[39m\u001b[39m*batch N N\u001b[39m\u001b[39m\"\u001b[39m], upper: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1296\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Float[LinearOperator, \u001b[39m\"\u001b[39m\u001b[39m*batch N N\u001b[39m\u001b[39m\"\u001b[39m]:  \u001b[39m# returns TriangularLinearOperator\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[39m    Cholesky-factorizes the LinearOperator.\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \n\u001b[1;32m   1300\u001b[0m \u001b[39m    :param upper: Upper triangular or lower triangular factor (default: False).\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[39m    :return: Cholesky factor (lower or upper triangular)\u001b[39;00m\n\u001b[1;32m   1302\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1303\u001b[0m     chol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cholesky(upper\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1304\u001b[0m     \u001b[39mif\u001b[39;00m upper:\n\u001b[1;32m   1305\u001b[0m         chol \u001b[39m=\u001b[39m chol\u001b[39m.\u001b[39m_transpose_nonbatch()\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/operators/_linear_operator.py:522\u001b[0m, in \u001b[0;36mLinearOperator._cholesky\u001b[0;34m(self, upper)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m TriangularLinearOperator(evaluated_mat\u001b[39m.\u001b[39mclamp_min(\u001b[39m0.0\u001b[39m)\u001b[39m.\u001b[39msqrt())\n\u001b[1;32m    521\u001b[0m \u001b[39m# contiguous call is necessary here\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m cholesky \u001b[39m=\u001b[39m psd_safe_cholesky(evaluated_mat, upper\u001b[39m=\u001b[39;49mupper)\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    523\u001b[0m \u001b[39mreturn\u001b[39;00m TriangularLinearOperator(cholesky, upper\u001b[39m=\u001b[39mupper)\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:65\u001b[0m, in \u001b[0;36mpsd_safe_cholesky\u001b[0;34m(A, upper, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpsd_safe_cholesky\u001b[39m(A, upper\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, jitter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_tries\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     51\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the Cholesky decomposition of A. If A is only p.s.d, add a small jitter to the diagonal.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m        :attr:`A` (Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m            Number of attempts (with successively increasing jitter) to make before raising an error.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     L \u001b[39m=\u001b[39m _psd_safe_cholesky(A, out\u001b[39m=\u001b[39;49mout, jitter\u001b[39m=\u001b[39;49mjitter, max_tries\u001b[39m=\u001b[39;49mmax_tries)\n\u001b[1;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m upper:\n\u001b[1;32m     67\u001b[0m         \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/firedrake/lib/python3.10/site-packages/linear_operator/utils/cholesky.py:47\u001b[0m, in \u001b[0;36m_psd_safe_cholesky\u001b[0;34m(A, out, jitter, max_tries)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39many(info):\n\u001b[1;32m     46\u001b[0m         \u001b[39mreturn\u001b[39;00m L\n\u001b[0;32m---> 47\u001b[0m \u001b[39mraise\u001b[39;00m NotPSDError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMatrix not positive definite after repeatedly adding jitter up to \u001b[39m\u001b[39m{\u001b[39;00mjitter_new\u001b[39m:\u001b[39;00m\u001b[39m.1e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNotPSDError\u001b[0m: Matrix not positive definite after repeatedly adding jitter up to 1.0e-04."
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "training_iter = 100\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(X)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        # model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firedrake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
